{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,GRU,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =pd.read_csv(\"reviews.txt\",delimiter='\\t',names=['Reviews','Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(['Sentiment'],axis=1)\n",
    "y=dataset.drop(['Reviews'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0  So there is no way for me to plug it in here i...\n",
       "1                        Good case, Excellent value.\n",
       "2                             Great for the jawbone.\n",
       "3  Tied to charger for conversations lasting more...\n",
       "4                                  The mic is great."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_series = dataset.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 38.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.fit_on_texts(X_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_words is None:\n",
    "    num_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'and': 3,\n",
       " 'it': 4,\n",
       " 'is': 5,\n",
       " 'a': 6,\n",
       " 'this': 7,\n",
       " 'to': 8,\n",
       " 'phone': 9,\n",
       " 'my': 10,\n",
       " 'for': 11,\n",
       " 'of': 12,\n",
       " 'not': 13,\n",
       " 'with': 14,\n",
       " 'very': 15,\n",
       " 'great': 16,\n",
       " 'was': 17,\n",
       " 'on': 18,\n",
       " 'in': 19,\n",
       " 'that': 20,\n",
       " 'good': 21,\n",
       " 'have': 22,\n",
       " 'you': 23,\n",
       " 'product': 24,\n",
       " 'quality': 25,\n",
       " 'had': 26,\n",
       " 'headset': 27,\n",
       " 'works': 28,\n",
       " 'battery': 29,\n",
       " 'but': 30,\n",
       " 'as': 31,\n",
       " 'sound': 32,\n",
       " 'so': 33,\n",
       " 'are': 34,\n",
       " 'well': 35,\n",
       " 'one': 36,\n",
       " 'all': 37,\n",
       " 'use': 38,\n",
       " 'ear': 39,\n",
       " 'has': 40,\n",
       " 'would': 41,\n",
       " 'work': 42,\n",
       " 'from': 43,\n",
       " 'your': 44,\n",
       " 'like': 45,\n",
       " 'be': 46,\n",
       " 'me': 47,\n",
       " 'case': 48,\n",
       " 'if': 49,\n",
       " 'than': 50,\n",
       " \"i've\": 51,\n",
       " \"don't\": 52,\n",
       " 'no': 53,\n",
       " 'excellent': 54,\n",
       " 'up': 55,\n",
       " 'time': 56,\n",
       " \"it's\": 57,\n",
       " 'after': 58,\n",
       " 'price': 59,\n",
       " 'recommend': 60,\n",
       " 'does': 61,\n",
       " 'really': 62,\n",
       " '2': 63,\n",
       " 'at': 64,\n",
       " 'or': 65,\n",
       " 'best': 66,\n",
       " 'out': 67,\n",
       " 'only': 68,\n",
       " 'service': 69,\n",
       " 'get': 70,\n",
       " 'when': 71,\n",
       " 'nice': 72,\n",
       " \"i'm\": 73,\n",
       " 'also': 74,\n",
       " 'too': 75,\n",
       " 'just': 76,\n",
       " 'any': 77,\n",
       " 'new': 78,\n",
       " 'love': 79,\n",
       " 'these': 80,\n",
       " 'worked': 81,\n",
       " 'am': 82,\n",
       " 'charger': 83,\n",
       " 'more': 84,\n",
       " 'money': 85,\n",
       " 'do': 86,\n",
       " 'can': 87,\n",
       " 'first': 88,\n",
       " 'buy': 89,\n",
       " 'item': 90,\n",
       " 'better': 91,\n",
       " 'an': 92,\n",
       " 'ever': 93,\n",
       " 'car': 94,\n",
       " 'bluetooth': 95,\n",
       " 'about': 96,\n",
       " 'even': 97,\n",
       " 'because': 98,\n",
       " 'easy': 99,\n",
       " 'then': 100,\n",
       " 'what': 101,\n",
       " 'comfortable': 102,\n",
       " 'bought': 103,\n",
       " 'now': 104,\n",
       " 'they': 105,\n",
       " 'reception': 106,\n",
       " 'could': 107,\n",
       " \"doesn't\": 108,\n",
       " 'its': 109,\n",
       " 'did': 110,\n",
       " 'used': 111,\n",
       " 'poor': 112,\n",
       " 'been': 113,\n",
       " 'happy': 114,\n",
       " 'which': 115,\n",
       " 'will': 116,\n",
       " 'there': 117,\n",
       " 'waste': 118,\n",
       " 'two': 119,\n",
       " 'charge': 120,\n",
       " 'made': 121,\n",
       " 'still': 122,\n",
       " 'off': 123,\n",
       " 'bad': 124,\n",
       " 'purchase': 125,\n",
       " 'few': 126,\n",
       " 'cell': 127,\n",
       " 'while': 128,\n",
       " 'worst': 129,\n",
       " 'them': 130,\n",
       " 'far': 131,\n",
       " 'long': 132,\n",
       " 'problem': 133,\n",
       " 'life': 134,\n",
       " 'fine': 135,\n",
       " 'camera': 136,\n",
       " 'calls': 137,\n",
       " 'enough': 138,\n",
       " 'thing': 139,\n",
       " 'device': 140,\n",
       " 'piece': 141,\n",
       " 'got': 142,\n",
       " 'same': 143,\n",
       " 'problems': 144,\n",
       " 'right': 145,\n",
       " 'volume': 146,\n",
       " 'again': 147,\n",
       " 'hear': 148,\n",
       " 'make': 149,\n",
       " 'clear': 150,\n",
       " 'much': 151,\n",
       " 'using': 152,\n",
       " 'motorola': 153,\n",
       " 'fit': 154,\n",
       " 'plug': 155,\n",
       " 'design': 156,\n",
       " 'makes': 157,\n",
       " 'other': 158,\n",
       " 'working': 159,\n",
       " 'fits': 160,\n",
       " 'into': 161,\n",
       " 'think': 162,\n",
       " 'people': 163,\n",
       " 'phones': 164,\n",
       " 'disappointed': 165,\n",
       " 'pretty': 166,\n",
       " 'looks': 167,\n",
       " 'call': 168,\n",
       " \"couldn't\": 169,\n",
       " 'screen': 170,\n",
       " 'over': 171,\n",
       " 'terrible': 172,\n",
       " 'impressed': 173,\n",
       " '5': 174,\n",
       " 'highly': 175,\n",
       " 'how': 176,\n",
       " 'days': 177,\n",
       " 'months': 178,\n",
       " 'years': 179,\n",
       " 'everything': 180,\n",
       " 'cool': 181,\n",
       " 'wear': 182,\n",
       " '1': 183,\n",
       " 'lot': 184,\n",
       " 'cheap': 185,\n",
       " 'customer': 186,\n",
       " 'low': 187,\n",
       " 'however': 188,\n",
       " 'amazon': 189,\n",
       " 'by': 190,\n",
       " 'last': 191,\n",
       " 'without': 192,\n",
       " 'talk': 193,\n",
       " 'little': 194,\n",
       " 'never': 195,\n",
       " '3': 196,\n",
       " 'their': 197,\n",
       " 'verizon': 198,\n",
       " 'buttons': 199,\n",
       " 'broke': 200,\n",
       " 'found': 201,\n",
       " 'tried': 202,\n",
       " 'light': 203,\n",
       " 'jabra': 204,\n",
       " 'small': 205,\n",
       " 'voice': 206,\n",
       " 'look': 207,\n",
       " 'being': 208,\n",
       " 'back': 209,\n",
       " 'horrible': 210,\n",
       " 'year': 211,\n",
       " 'junk': 212,\n",
       " 'unit': 213,\n",
       " 'way': 214,\n",
       " 'several': 215,\n",
       " 'say': 216,\n",
       " 'went': 217,\n",
       " 'most': 218,\n",
       " \"didn't\": 219,\n",
       " 'audio': 220,\n",
       " 'dropped': 221,\n",
       " 'we': 222,\n",
       " 'loud': 223,\n",
       " 'real': 224,\n",
       " 'since': 225,\n",
       " 'big': 226,\n",
       " 'headsets': 227,\n",
       " 'gets': 228,\n",
       " 'down': 229,\n",
       " 'both': 230,\n",
       " 'completely': 231,\n",
       " 'software': 232,\n",
       " 'some': 233,\n",
       " 'internet': 234,\n",
       " 'useless': 235,\n",
       " 'company': 236,\n",
       " 'nokia': 237,\n",
       " 'quite': 238,\n",
       " 'looking': 239,\n",
       " 'take': 240,\n",
       " 'go': 241,\n",
       " 'minutes': 242,\n",
       " 'going': 243,\n",
       " 'three': 244,\n",
       " 'simple': 245,\n",
       " 'ears': 246,\n",
       " 'need': 247,\n",
       " 'picture': 248,\n",
       " 'priced': 249,\n",
       " 'want': 250,\n",
       " 'end': 251,\n",
       " 'headphones': 252,\n",
       " 'find': 253,\n",
       " 'within': 254,\n",
       " 'received': 255,\n",
       " 'black': 256,\n",
       " 'around': 257,\n",
       " 'signal': 258,\n",
       " 'perfectly': 259,\n",
       " 'less': 260,\n",
       " 'put': 261,\n",
       " 'every': 262,\n",
       " 'stay': 263,\n",
       " 'before': 264,\n",
       " 'cable': 265,\n",
       " 'hands': 266,\n",
       " 'came': 267,\n",
       " 'crap': 268,\n",
       " 'anyone': 269,\n",
       " 'difficult': 270,\n",
       " 'samsung': 271,\n",
       " 'value': 272,\n",
       " 'line': 273,\n",
       " 'razr': 274,\n",
       " 'original': 275,\n",
       " 'started': 276,\n",
       " 'charging': 277,\n",
       " 'mobile': 278,\n",
       " 'helpful': 279,\n",
       " 'hold': 280,\n",
       " 'sure': 281,\n",
       " 'turn': 282,\n",
       " 'sturdy': 283,\n",
       " 'different': 284,\n",
       " 'week': 285,\n",
       " 'feels': 286,\n",
       " 'arrived': 287,\n",
       " 'quickly': 288,\n",
       " 'expect': 289,\n",
       " 'definitely': 290,\n",
       " 'free': 291,\n",
       " 'shipping': 292,\n",
       " 'pictures': 293,\n",
       " 'high': 294,\n",
       " 'strong': 295,\n",
       " 'pleased': 296,\n",
       " 'job': 297,\n",
       " 'weeks': 298,\n",
       " 'hours': 299,\n",
       " 'know': 300,\n",
       " 'kind': 301,\n",
       " 'charm': 302,\n",
       " 'awesome': 303,\n",
       " 'where': 304,\n",
       " 'overall': 305,\n",
       " 'color': 306,\n",
       " 'part': 307,\n",
       " 'range': 308,\n",
       " \"i'd\": 309,\n",
       " 'disappointment': 310,\n",
       " 'important': 311,\n",
       " 'return': 312,\n",
       " 'feature': 313,\n",
       " 'many': 314,\n",
       " 'old': 315,\n",
       " 'anything': 316,\n",
       " 'couple': 317,\n",
       " 'disappointing': 318,\n",
       " 'belt': 319,\n",
       " 'data': 320,\n",
       " 'having': 321,\n",
       " 'especially': 322,\n",
       " 'keep': 323,\n",
       " 'plastic': 324,\n",
       " 'another': 325,\n",
       " 'clarity': 326,\n",
       " 'nothing': 327,\n",
       " 'hard': 328,\n",
       " 'always': 329,\n",
       " 'replace': 330,\n",
       " 'none': 331,\n",
       " 'cannot': 332,\n",
       " 'cases': 333,\n",
       " 'connection': 334,\n",
       " \"can't\": 335,\n",
       " 'easily': 336,\n",
       " 'here': 337,\n",
       " 'mic': 338,\n",
       " 'decent': 339,\n",
       " 'sending': 340,\n",
       " 'must': 341,\n",
       " 'were': 342,\n",
       " 'clip': 343,\n",
       " 'blue': 344,\n",
       " 'place': 345,\n",
       " 'absolutely': 346,\n",
       " 'bars': 347,\n",
       " 'she': 348,\n",
       " 'instructions': 349,\n",
       " 'left': 350,\n",
       " 'hate': 351,\n",
       " 'kept': 352,\n",
       " 'performance': 353,\n",
       " 'seems': 354,\n",
       " 'should': 355,\n",
       " 'keyboard': 356,\n",
       " 'actually': 357,\n",
       " 'support': 358,\n",
       " 'player': 359,\n",
       " 'later': 360,\n",
       " 'purchased': 361,\n",
       " 'holds': 362,\n",
       " 'bargain': 363,\n",
       " 'order': 364,\n",
       " 'leather': 365,\n",
       " 'fast': 366,\n",
       " 'comfortably': 367,\n",
       " 'set': 368,\n",
       " 'glad': 369,\n",
       " 'goes': 370,\n",
       " 'tool': 371,\n",
       " 'obviously': 372,\n",
       " 'side': 373,\n",
       " '10': 374,\n",
       " 'lasts': 375,\n",
       " 'able': 376,\n",
       " 'lightweight': 377,\n",
       " 'expected': 378,\n",
       " 'mistake': 379,\n",
       " 'worth': 380,\n",
       " 'earpiece': 381,\n",
       " 'either': 382,\n",
       " 'unreliable': 383,\n",
       " 'family': 384,\n",
       " 'seller': 385,\n",
       " 'plantronics': 386,\n",
       " 'buying': 387,\n",
       " 'try': 388,\n",
       " 'weak': 389,\n",
       " 'lg': 390,\n",
       " 'sucks': 391,\n",
       " 'ago': 392,\n",
       " 'times': 393,\n",
       " 'easier': 394,\n",
       " 'face': 395,\n",
       " 'others': 396,\n",
       " 'wanted': 397,\n",
       " 'deal': 398,\n",
       " 'satisfied': 399,\n",
       " 'comes': 400,\n",
       " 'rather': 401,\n",
       " 'away': 402,\n",
       " 'unfortunately': 403,\n",
       " 'those': 404,\n",
       " 'store': 405,\n",
       " 'own': 406,\n",
       " 'cingular': 407,\n",
       " 't': 408,\n",
       " 'ringtones': 409,\n",
       " 'said': 410,\n",
       " 'day': 411,\n",
       " 'treo': 412,\n",
       " 'usb': 413,\n",
       " 'extra': 414,\n",
       " 'awful': 415,\n",
       " 'unless': 416,\n",
       " 'jawbone': 417,\n",
       " 'conversations': 418,\n",
       " 'contacts': 419,\n",
       " 'static': 420,\n",
       " 'though': 421,\n",
       " 'who': 422,\n",
       " 'everyone': 423,\n",
       " 'pair': 424,\n",
       " 'yet': 425,\n",
       " 'below': 426,\n",
       " 'pocket': 427,\n",
       " 'pc': 428,\n",
       " 'provided': 429,\n",
       " 'included': 430,\n",
       " 'worthless': 431,\n",
       " 'thats': 432,\n",
       " 'features': 433,\n",
       " 'protection': 434,\n",
       " 'instead': 435,\n",
       " 'seconds': 436,\n",
       " '510': 437,\n",
       " 'perhaps': 438,\n",
       " 'seriously': 439,\n",
       " \"phone's\": 440,\n",
       " 'front': 441,\n",
       " 'trouble': 442,\n",
       " 'choice': 443,\n",
       " 'home': 444,\n",
       " 'beautiful': 445,\n",
       " 'longer': 446,\n",
       " 'packaged': 447,\n",
       " 'construction': 448,\n",
       " 'super': 449,\n",
       " 'ease': 450,\n",
       " 'dont': 451,\n",
       " 'plan': 452,\n",
       " 'decision': 453,\n",
       " 'match': 454,\n",
       " 'between': 455,\n",
       " 'fall': 456,\n",
       " 'such': 457,\n",
       " 'wife': 458,\n",
       " 'display': 459,\n",
       " 'rocks': 460,\n",
       " 'may': 461,\n",
       " 'setup': 462,\n",
       " 'earpieces': 463,\n",
       " 'bt': 464,\n",
       " 'getting': 465,\n",
       " 'almost': 466,\n",
       " 'avoid': 467,\n",
       " 'earbud': 468,\n",
       " 'failed': 469,\n",
       " 'coverage': 470,\n",
       " 'drops': 471,\n",
       " 'area': 472,\n",
       " 'forever': 473,\n",
       " 'description': 474,\n",
       " 'fantastic': 475,\n",
       " 'sharp': 476,\n",
       " 'chargers': 477,\n",
       " 'handsfree': 478,\n",
       " 'network': 479,\n",
       " 'slow': 480,\n",
       " 'once': 481,\n",
       " 'lost': 482,\n",
       " 'replacement': 483,\n",
       " 'extremely': 484,\n",
       " 'simply': 485,\n",
       " 'thought': 486,\n",
       " 'reasonably': 487,\n",
       " 'form': 488,\n",
       " 'experience': 489,\n",
       " \"there's\": 490,\n",
       " 'ordered': 491,\n",
       " 'sony': 492,\n",
       " 'market': 493,\n",
       " 'comfort': 494,\n",
       " 'probably': 495,\n",
       " 'drain': 496,\n",
       " 'poorly': 497,\n",
       " 'charged': 498,\n",
       " 'scratched': 499,\n",
       " 'microphone': 500,\n",
       " 'care': 501,\n",
       " 'lacking': 502,\n",
       " 'uncomfortable': 503,\n",
       " 'plugged': 504,\n",
       " 'flip': 505,\n",
       " 'wireless': 506,\n",
       " 'happier': 507,\n",
       " 'trying': 508,\n",
       " 'finally': 509,\n",
       " 'give': 510,\n",
       " 'dead': 511,\n",
       " 'oh': 512,\n",
       " 'might': 513,\n",
       " 'q': 514,\n",
       " 'size': 515,\n",
       " \"wasn't\": 516,\n",
       " 'expensive': 517,\n",
       " 'turned': 518,\n",
       " 'wearing': 519,\n",
       " 'computer': 520,\n",
       " 'under': 521,\n",
       " 'results': 522,\n",
       " 'wrong': 523,\n",
       " 'noise': 524,\n",
       " 'given': 525,\n",
       " 'star': 526,\n",
       " 'holster': 527,\n",
       " 'palm': 528,\n",
       " 'refund': 529,\n",
       " 'drop': 530,\n",
       " 'above': 531,\n",
       " 'through': 532,\n",
       " 'speaker': 533,\n",
       " 'sprint': 534,\n",
       " 'feel': 535,\n",
       " 'needed': 536,\n",
       " 'plus': 537,\n",
       " 'pay': 538,\n",
       " 'tinny': 539,\n",
       " 'pairing': 540,\n",
       " 'iphone': 541,\n",
       " 'despite': 542,\n",
       " 'outlet': 543,\n",
       " 'break': 544,\n",
       " 'beep': 545,\n",
       " 'us': 546,\n",
       " 'lasting': 547,\n",
       " 'wasted': 548,\n",
       " 'he': 549,\n",
       " 'extended': 550,\n",
       " 'notice': 551,\n",
       " 'tooth': 552,\n",
       " 'advise': 553,\n",
       " 'website': 554,\n",
       " 'fire': 555,\n",
       " 'run': 556,\n",
       " \"that's\": 557,\n",
       " 'owned': 558,\n",
       " '7': 559,\n",
       " 'pull': 560,\n",
       " 'unusable': 561,\n",
       " 'least': 562,\n",
       " 'book': 563,\n",
       " 'regarding': 564,\n",
       " 'returned': 565,\n",
       " 'turns': 566,\n",
       " 'pda': 567,\n",
       " 'large': 568,\n",
       " 'essentially': 569,\n",
       " 'forget': 570,\n",
       " 'tech': 571,\n",
       " 'particular': 572,\n",
       " 'party': 573,\n",
       " 'clearly': 574,\n",
       " 'mp3': 575,\n",
       " 'cover': 576,\n",
       " 'let': 577,\n",
       " 'lock': 578,\n",
       " 'died': 579,\n",
       " 'glasses': 580,\n",
       " 'sometimes': 581,\n",
       " 'series': 582,\n",
       " 'quiet': 583,\n",
       " 'person': 584,\n",
       " 'saying': 585,\n",
       " 'docking': 586,\n",
       " 'station': 587,\n",
       " 'd807': 588,\n",
       " 'advertised': 589,\n",
       " 'handy': 590,\n",
       " '6': 591,\n",
       " 'loves': 592,\n",
       " 'cheaper': 593,\n",
       " 'costs': 594,\n",
       " 'play': 595,\n",
       " 'music': 596,\n",
       " 'buyer': 597,\n",
       " 'beware': 598,\n",
       " 'pros': 599,\n",
       " 'white': 600,\n",
       " 'huge': 601,\n",
       " 'flaw': 602,\n",
       " 'although': 603,\n",
       " 'impressive': 604,\n",
       " 'resolution': 605,\n",
       " 'ask': 606,\n",
       " 'slim': 607,\n",
       " 'sex': 608,\n",
       " 'sleek': 609,\n",
       " 'full': 610,\n",
       " 'number': 611,\n",
       " 'keypad': 612,\n",
       " 'unhappy': 613,\n",
       " 'done': 614,\n",
       " 'basically': 615,\n",
       " 'careful': 616,\n",
       " 'logitech': 617,\n",
       " 'stuff': 618,\n",
       " 'house': 619,\n",
       " 'recognition': 620,\n",
       " 'tremendous': 621,\n",
       " 'during': 622,\n",
       " 'experienced': 623,\n",
       " 'takes': 624,\n",
       " 'literally': 625,\n",
       " 'stated': 626,\n",
       " 'hoping': 627,\n",
       " 'blackberry': 628,\n",
       " 'sounds': 629,\n",
       " 'technology': 630,\n",
       " \"wouldn't\": 631,\n",
       " 'wired': 632,\n",
       " 'previous': 633,\n",
       " 'w810i': 634,\n",
       " 'superb': 635,\n",
       " 'maintain': 636,\n",
       " 'graphics': 637,\n",
       " 'button': 638,\n",
       " 'thank': 639,\n",
       " 'igo': 640,\n",
       " 'tips': 641,\n",
       " 'connected': 642,\n",
       " \"wife's\": 643,\n",
       " 'storage': 644,\n",
       " 'buzzing': 645,\n",
       " 'override': 646,\n",
       " 'functionality': 647,\n",
       " 'incredible': 648,\n",
       " 'ring': 649,\n",
       " 'dropping': 650,\n",
       " 'thin': 651,\n",
       " 'nearly': 652,\n",
       " 'bother': 653,\n",
       " 'room': 654,\n",
       " 'issues': 655,\n",
       " 'felt': 656,\n",
       " 'embarrassing': 657,\n",
       " 'consumer': 658,\n",
       " 'background': 659,\n",
       " 'certainly': 660,\n",
       " 'usually': 661,\n",
       " 'mess': 662,\n",
       " 'bit': 663,\n",
       " 'tell': 664,\n",
       " 'excited': 665,\n",
       " 'additional': 666,\n",
       " 'gels': 667,\n",
       " 'whatsoever': 668,\n",
       " 'purpose': 669,\n",
       " 'secure': 670,\n",
       " 'appears': 671,\n",
       " 'smell': 672,\n",
       " 'caused': 673,\n",
       " 'flimsy': 674,\n",
       " 'month': 675,\n",
       " 'flawlessly': 676,\n",
       " 'stars': 677,\n",
       " 'whole': 678,\n",
       " 'adorable': 679,\n",
       " 'wise': 680,\n",
       " 'gotten': 681,\n",
       " 'driving': 682,\n",
       " 'dialing': 683,\n",
       " 'cant': 684,\n",
       " 'neither': 685,\n",
       " 'games': 686,\n",
       " 'ipod': 687,\n",
       " 'recharge': 688,\n",
       " 'save': 689,\n",
       " \"i'll\": 690,\n",
       " 'along': 691,\n",
       " 'starts': 692,\n",
       " 'ringing': 693,\n",
       " 'reason': 694,\n",
       " 'auto': 695,\n",
       " 'push': 696,\n",
       " 'sides': 697,\n",
       " 'skype': 698,\n",
       " 'shipped': 699,\n",
       " 'exactly': 700,\n",
       " 'waiting': 701,\n",
       " 'stupid': 702,\n",
       " 'noticed': 703,\n",
       " 'att': 704,\n",
       " 'breaks': 705,\n",
       " 'effect': 706,\n",
       " 'model': 707,\n",
       " 'warning': 708,\n",
       " 'dying': 709,\n",
       " 'alone': 710,\n",
       " 'install': 711,\n",
       " 'purchasing': 712,\n",
       " 'moto': 713,\n",
       " 'figure': 714,\n",
       " '20': 715,\n",
       " 'reading': 716,\n",
       " 'sunglasses': 717,\n",
       " 'returning': 718,\n",
       " 'cumbersome': 719,\n",
       " 'switch': 720,\n",
       " 'worthwhile': 721,\n",
       " 'understand': 722,\n",
       " 'batteries': 723,\n",
       " \"won't\": 724,\n",
       " 'user': 725,\n",
       " 'friendly': 726,\n",
       " 'ability': 727,\n",
       " 'receiving': 728,\n",
       " 'exchanged': 729,\n",
       " 'cellphone': 730,\n",
       " 'described': 731,\n",
       " 'im': 732,\n",
       " 'defective': 733,\n",
       " 'unacceptable': 734,\n",
       " 'review': 735,\n",
       " 'catching': 736,\n",
       " 'amazed': 737,\n",
       " 'timeframe': 738,\n",
       " 'complaint': 739,\n",
       " 'things': 740,\n",
       " 'ended': 741,\n",
       " 'accidentally': 742,\n",
       " 'touch': 743,\n",
       " 'listening': 744,\n",
       " 'took': 745,\n",
       " 'conversation': 746,\n",
       " 'eargels': 747,\n",
       " 'seem': 748,\n",
       " 'numerous': 749,\n",
       " 'please': 750,\n",
       " 'barely': 751,\n",
       " 'joke': 752,\n",
       " 'forced': 753,\n",
       " 'holding': 754,\n",
       " 'broken': 755,\n",
       " 'breaking': 756,\n",
       " '50': 757,\n",
       " 'coming': 758,\n",
       " 'quick': 759,\n",
       " 'operate': 760,\n",
       " 'paired': 761,\n",
       " 'come': 762,\n",
       " 'brand': 763,\n",
       " 'red': 764,\n",
       " 'reviews': 765,\n",
       " 'echo': 766,\n",
       " 'wind': 767,\n",
       " 'told': 768,\n",
       " 'warranty': 769,\n",
       " 'something': 770,\n",
       " 'bar': 771,\n",
       " 'placed': 772,\n",
       " 'spring': 773,\n",
       " 'tries': 774,\n",
       " 'download': 775,\n",
       " 'access': 776,\n",
       " 'third': 777,\n",
       " 'flash': 778,\n",
       " 'tones': 779,\n",
       " 'chinese': 780,\n",
       " 'crisp': 781,\n",
       " 'video': 782,\n",
       " 'hour': 783,\n",
       " 'accept': 784,\n",
       " 'allows': 785,\n",
       " 'power': 786,\n",
       " 'wall': 787,\n",
       " 'etc': 788,\n",
       " 'hand': 789,\n",
       " 'cut': 790,\n",
       " 'sizes': 791,\n",
       " '4': 792,\n",
       " 'next': 793,\n",
       " 'protector': 794,\n",
       " 'date': 795,\n",
       " 'bottom': 796,\n",
       " 'sounded': 797,\n",
       " 'together': 798,\n",
       " 'feet': 799,\n",
       " 'send': 800,\n",
       " 'current': 801,\n",
       " 'says': 802,\n",
       " 'answer': 803,\n",
       " 'laptop': 804,\n",
       " 'inside': 805,\n",
       " 'normal': 806,\n",
       " 'making': 807,\n",
       " 'fails': 808,\n",
       " 'lose': 809,\n",
       " 'ok': 810,\n",
       " 'wow': 811,\n",
       " 'converter': 812,\n",
       " 'tied': 813,\n",
       " '45': 814,\n",
       " 'major': 815,\n",
       " 'jiggle': 816,\n",
       " 'dozen': 817,\n",
       " 'hundred': 818,\n",
       " 'imagine': 819,\n",
       " 'fun': 820,\n",
       " 'each': 821,\n",
       " 'owner': 822,\n",
       " 'needless': 823,\n",
       " 'seperated': 824,\n",
       " 'mere': 825,\n",
       " 'ft': 826,\n",
       " 'excessive': 827,\n",
       " 'garbled': 828,\n",
       " 'odd': 829,\n",
       " 'fooled': 830,\n",
       " 'clicks': 831,\n",
       " 'wonder': 832,\n",
       " 'mechanism': 833,\n",
       " \"motorola's\": 834,\n",
       " 'followed': 835,\n",
       " 'directions': 836,\n",
       " 'kindle': 837,\n",
       " 'loved': 838,\n",
       " 'commercials': 839,\n",
       " 'misleading': 840,\n",
       " 'mother': 841,\n",
       " 'combination': 842,\n",
       " 'couldnt': 843,\n",
       " 'earphone': 844,\n",
       " 'breakage': 845,\n",
       " 'unacceptible': 846,\n",
       " 'ideal': 847,\n",
       " 'whose': 848,\n",
       " 'sensitive': 849,\n",
       " 'moving': 850,\n",
       " 'freeway': 851,\n",
       " 'speed': 852,\n",
       " 'contract': 853,\n",
       " 'ac': 854,\n",
       " 'juice': 855,\n",
       " 'highy': 856,\n",
       " 'recommended': 857,\n",
       " 'mins': 858,\n",
       " 'short': 859,\n",
       " '680': 860,\n",
       " '2mp': 861,\n",
       " 'pics': 862,\n",
       " 'garbage': 863,\n",
       " 'mind': 864,\n",
       " 'gonna': 865,\n",
       " 'arguing': 866,\n",
       " 'bulky': 867,\n",
       " 'usable': 868,\n",
       " 'world': 869,\n",
       " 'useful': 870,\n",
       " 'machine': 871,\n",
       " 'neat': 872,\n",
       " 'gadget': 873,\n",
       " 'reasonable': 874,\n",
       " 'e': 875,\n",
       " 'stream': 876,\n",
       " 'submerged': 877,\n",
       " '15': 878,\n",
       " 'complaints': 879,\n",
       " \"microsoft's\": 880,\n",
       " 'faceplates': 881,\n",
       " 'elegant': 882,\n",
       " 'angle': 883,\n",
       " 'drawback': 884,\n",
       " 'pause': 885,\n",
       " 'skip': 886,\n",
       " 'songs': 887,\n",
       " 'activated': 888,\n",
       " 'suddenly': 889,\n",
       " 'ipods': 890,\n",
       " 'situations': 891,\n",
       " 'bmw': 892,\n",
       " 'fairly': 893,\n",
       " 'hearing': 894,\n",
       " 'wrongly': 895,\n",
       " 'everyday': 896,\n",
       " 'intended': 897,\n",
       " 'runs': 898,\n",
       " 'boy': 899,\n",
       " 'loads': 900,\n",
       " 'greater': 901,\n",
       " 'buds': 902,\n",
       " 'waaay': 903,\n",
       " 'bluetooths': 904,\n",
       " 'listener': 905,\n",
       " 'integrated': 906,\n",
       " 'seamlessly': 907,\n",
       " 'flush': 908,\n",
       " 'toilet': 909,\n",
       " 'supposedly': 910,\n",
       " '375': 911,\n",
       " 'apparently': 912,\n",
       " 'styles': 913,\n",
       " 'correctly': 914,\n",
       " '350': 915,\n",
       " 'jabra350': 916,\n",
       " 'rated': 917,\n",
       " 'megapixels': 918,\n",
       " 'renders': 919,\n",
       " 'images': 920,\n",
       " 'expectations': 921,\n",
       " 'relatively': 922,\n",
       " 'purcashed': 923,\n",
       " 'geeky': 924,\n",
       " 'toast': 925,\n",
       " 'oozes': 926,\n",
       " 'embedded': 927,\n",
       " 'stylish': 928,\n",
       " 'compromise': 929,\n",
       " 'qwerty': 930,\n",
       " 'basic': 931,\n",
       " 'winner': 932,\n",
       " 'simpler': 933,\n",
       " 'iam': 934,\n",
       " 'disapoinment': 935,\n",
       " 'realize': 936,\n",
       " 'accompanied': 937,\n",
       " 'brilliant': 938,\n",
       " 'nicely': 939,\n",
       " 'damage': 940,\n",
       " 'definitly': 941,\n",
       " 'majority': 942,\n",
       " 'peachy': 943,\n",
       " 'keen': 944,\n",
       " 'upstairs': 945,\n",
       " 'basement': 946,\n",
       " 'minute': 947,\n",
       " 'reccomendation': 948,\n",
       " 'relative': 949,\n",
       " 'items': 950,\n",
       " 'sudden': 951,\n",
       " 'linking': 952,\n",
       " '8530': 953,\n",
       " 'curve': 954,\n",
       " 'funny': 955,\n",
       " 'seemed': 956,\n",
       " 'sketchy': 957,\n",
       " 'messages': 958,\n",
       " 'web': 959,\n",
       " 'browsing': 960,\n",
       " 'significantly': 961,\n",
       " 'faster': 962,\n",
       " 'build': 963,\n",
       " 'unlike': 964,\n",
       " 's': 965,\n",
       " 'colors': 966,\n",
       " 'whine': 967,\n",
       " 'communications': 968,\n",
       " 'communicate': 969,\n",
       " 'monkeys': 970,\n",
       " \"shouldn't\": 971,\n",
       " 'share': 972,\n",
       " 'dna': 973,\n",
       " 'copy': 974,\n",
       " 'humans': 975,\n",
       " 'bougth': 976,\n",
       " 'l7c': 977,\n",
       " 'mode': 978,\n",
       " 'wasting': 979,\n",
       " 'file': 980,\n",
       " 'browser': 981,\n",
       " 'offers': 982,\n",
       " 'options': 983,\n",
       " 'needs': 984,\n",
       " 'hs850': 985,\n",
       " 'whether': 986,\n",
       " 'latest': 987,\n",
       " 'os': 988,\n",
       " 'v1': 989,\n",
       " '15g': 990,\n",
       " 'likes': 991,\n",
       " 'crawl': 992,\n",
       " 'recognizes': 993,\n",
       " 'bluetoooth': 994,\n",
       " 'thorn': 995,\n",
       " 'abhor': 996,\n",
       " 'recently': 997,\n",
       " 'disconnected': 998,\n",
       " '13': 999,\n",
       " 'bucks': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993    0\n",
       "859    0\n",
       "298    0\n",
       "553    1\n",
       "672    0\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = X_train['Reviews']\n",
    "x_test = X_test['Reviews']\n",
    "Y_test = y_test['Sentiment']\n",
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([404, 164,  34, 159,  76, 135, 104])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180,  96,   4,   5, 135,   3, 874,  11,   1,  59,   2, 875])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_test_tokens[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre'\n",
    "max_tokens = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen = max_tokens, padding = pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pad = pad_sequences(x_test_tokens, maxlen = max_tokens, padding = pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167,  21,  19,   1, 248,  30,   7,  48,  17,   6, 601, 310])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0, 167,  21,  19,   1, 248,\n",
       "        30,   7,  48,  17,   6, 601, 310])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim = num_words,\n",
    "                   output_dim = 8,\n",
    "                   input_length = max_tokens,\n",
    "                   name = 'layer_embedding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units = 16, return_sequences = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units = 8, return_sequences = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_embedding (Embedding)  (None, 20, 8)            16000     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 20, 16)            1248      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 20, 8)             624       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 4)                 168       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,045\n",
      "Trainable params: 18,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "24/24 [==============================] - 11s 33ms/step - loss: 0.6931 - accuracy: 0.5093\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.6869 - accuracy: 0.5907\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.6664 - accuracy: 0.7307\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.5834 - accuracy: 0.7560\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4192 - accuracy: 0.8573\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2570 - accuracy: 0.9440\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1814 - accuracy: 0.9613\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1380 - accuracy: 0.9813\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1265 - accuracy: 0.9787\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0950 - accuracy: 0.9947\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0749 - accuracy: 0.9960\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0645 - accuracy: 0.9960\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0661 - accuracy: 0.9933\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0512 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0316 - accuracy: 0.9987\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0011 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1957694ce80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, y_train, epochs =150, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.round(result, decimals = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  0.0\n",
       "1  0.0\n",
       "2  0.0\n",
       "3  1.0\n",
       "4  0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88,  32],\n",
       "       [ 30, 100]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = accuracy_score(y_test, result)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.75      0.73      0.74       120\\n           1       0.76      0.77      0.76       130\\n\\n    accuracy                           0.75       250\\n   macro avg       0.75      0.75      0.75       250\\nweighted avg       0.75      0.75      0.75       250\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = classification_report(y_test, result)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
